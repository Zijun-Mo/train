"""
èåˆæ¨¡å‹å®šä¹‰ - ç»“åˆå…‰æµå’Œå…³é”®ç‚¹ç‰¹å¾
"""
import torch
import torch.nn as nn
from typing import Dict, Any


class FusionModel(nn.Module):
    """ç‰¹å¾èåˆæ¨¡å‹"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–èåˆæ¨¡å‹
        
        Args:
            config: æ¨¡å‹é…ç½®
        """
        super(FusionModel, self).__init__()
        
        self.input_dim = config.get('input_dim', 4)  # 2 + 2
        self.hidden_dims = config.get('hidden_dims', [16, 8])
        self.output_dim = config.get('output_dim', 2)
        self.dropout = config.get('dropout', 0.2)
        self.activation = config.get('activation', 'relu')
        
        # æ„å»ºç½‘ç»œ
        self._build_network()
    
    def _build_network(self):
        """æ„å»ºèåˆç½‘ç»œ"""
        layers = []
        
        # è¾“å…¥å±‚
        prev_dim = self.input_dim
        
        # éšè—å±‚
        for hidden_dim in self.hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.BatchNorm1d(hidden_dim),
                self._get_activation(),
                nn.Dropout(self.dropout)
            ])
            prev_dim = hidden_dim
        
        # è¾“å‡ºå±‚
        layers.append(nn.Linear(prev_dim, self.output_dim))
        
        self.network = nn.Sequential(*layers)
    
    def _get_activation(self):
        """è·å–æ¿€æ´»å‡½æ•°"""
        if self.activation == 'relu':
            return nn.ReLU(inplace=True)
        elif self.activation == 'leaky_relu':
            return nn.LeakyReLU(0.1, inplace=True)
        elif self.activation == 'elu':
            return nn.ELU(inplace=True)
        elif self.activation == 'gelu':
            return nn.GELU()
        elif self.activation == 'tanh':
            return nn.Tanh()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¿€æ´»å‡½æ•°: {self.activation}")
    
    def forward(self, optical_flow_features: torch.Tensor, 
                landmark_features: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            optical_flow_features: å…‰æµç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(batch_size, 2)
            landmark_features: å…³é”®ç‚¹ç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(batch_size, 2)
            
        Returns:
            èåˆåçš„è¾“å‡ºï¼Œå½¢çŠ¶ä¸º(batch_size, 2)
        """
        # æ‹¼æ¥ç‰¹å¾
        combined_features = torch.cat([optical_flow_features, landmark_features], dim=1)
        
        # é€šè¿‡èåˆç½‘ç»œ
        output = self.network(combined_features)
        
        return output


class AdvancedFusionModel(nn.Module):
    """é«˜çº§èåˆæ¨¡å‹ï¼ŒåŒ…å«äº¤å‰æ³¨æ„åŠ›æœºåˆ¶"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–é«˜çº§èåˆæ¨¡å‹
        
        Args:
            config: æ¨¡å‹é…ç½®
        """
        super(AdvancedFusionModel, self).__init__()
        
        self.feature_dim = 2  # æ¯ä¸ªæ¨¡æ€çš„ç‰¹å¾ç»´åº¦
        self.hidden_dims = config.get('hidden_dims', [16, 8])
        self.output_dim = config.get('output_dim', 2)
        self.dropout = config.get('dropout', 0.2)
        self.use_attention = config.get('use_attention', True)
        
        # ç‰¹å¾æŠ•å½±å±‚
        self.optical_flow_proj = nn.Linear(self.feature_dim, 8)
        self.landmark_proj = nn.Linear(self.feature_dim, 8)
        
        # äº¤å‰æ³¨æ„åŠ›æœºåˆ¶
        if self.use_attention:
            self.cross_attention = CrossModalAttention(8)
        
        # èåˆç½‘ç»œ
        fusion_input_dim = 16 if self.use_attention else 4
        self.fusion_network = self._build_fusion_network(fusion_input_dim)
    
    def _build_fusion_network(self, input_dim: int):
        """æ„å»ºèåˆç½‘ç»œ"""
        layers = []
        
        prev_dim = input_dim
        for hidden_dim in self.hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.BatchNorm1d(hidden_dim),
                nn.ReLU(inplace=True),
                nn.Dropout(self.dropout)
            ])
            prev_dim = hidden_dim
        
        layers.append(nn.Linear(prev_dim, self.output_dim))
        
        return nn.Sequential(*layers)
    
    def forward(self, optical_flow_features: torch.Tensor, 
                landmark_features: torch.Tensor) -> torch.Tensor:
        """å‰å‘ä¼ æ’­"""
        # ç‰¹å¾æŠ•å½±
        optical_proj = self.optical_flow_proj(optical_flow_features)
        landmark_proj = self.landmark_proj(landmark_features)
        
        if self.use_attention:
            # äº¤å‰æ³¨æ„åŠ›
            attended_optical, attended_landmark = self.cross_attention(optical_proj, landmark_proj)
            # æ‹¼æ¥æ³¨æ„åŠ›åçš„ç‰¹å¾
            combined = torch.cat([attended_optical, attended_landmark], dim=1)
        else:
            # ç›´æ¥æ‹¼æ¥
            combined = torch.cat([optical_proj, landmark_proj], dim=1)
        
        # èåˆç½‘ç»œ
        output = self.fusion_network(combined)
        
        return output


class CrossModalAttention(nn.Module):
    """è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶"""
    
    def __init__(self, dim: int):
        super(CrossModalAttention, self).__init__()
        
        self.dim = dim
        
        # æŸ¥è¯¢ã€é”®ã€å€¼æŠ•å½±
        self.optical_query = nn.Linear(dim, dim)
        self.optical_key = nn.Linear(dim, dim)
        self.optical_value = nn.Linear(dim, dim)
        
        self.landmark_query = nn.Linear(dim, dim)
        self.landmark_key = nn.Linear(dim, dim)
        self.landmark_value = nn.Linear(dim, dim)
        
        self.softmax = nn.Softmax(dim=-1)
        
    def forward(self, optical_features: torch.Tensor, 
                landmark_features: torch.Tensor) -> tuple:
        """
        äº¤å‰æ³¨æ„åŠ›è®¡ç®—
        
        Args:
            optical_features: å…‰æµç‰¹å¾
            landmark_features: å…³é”®ç‚¹ç‰¹å¾
            
        Returns:
            æ³¨æ„åŠ›åŠ æƒåçš„ç‰¹å¾
        """
        batch_size = optical_features.size(0)
        
        # å…‰æµç‰¹å¾å…³æ³¨å…³é”®ç‚¹ç‰¹å¾
        optical_q = self.optical_query(optical_features).unsqueeze(1)
        landmark_k = self.landmark_key(landmark_features).unsqueeze(1)
        landmark_v = self.landmark_value(landmark_features).unsqueeze(1)
        
        optical_attention_scores = torch.matmul(optical_q, landmark_k.transpose(-2, -1)) / (self.dim ** 0.5)
        optical_attention_weights = self.softmax(optical_attention_scores)
        attended_optical = torch.matmul(optical_attention_weights, landmark_v).squeeze(1)
        
        # å…³é”®ç‚¹ç‰¹å¾å…³æ³¨å…‰æµç‰¹å¾
        landmark_q = self.landmark_query(landmark_features).unsqueeze(1)
        optical_k = self.optical_key(optical_features).unsqueeze(1)
        optical_v = self.optical_value(optical_features).unsqueeze(1)
        
        landmark_attention_scores = torch.matmul(landmark_q, optical_k.transpose(-2, -1)) / (self.dim ** 0.5)
        landmark_attention_weights = self.softmax(landmark_attention_scores)
        attended_landmark = torch.matmul(landmark_attention_weights, optical_v).squeeze(1)
        
        return attended_optical, attended_landmark


class CompleteFusionModel(nn.Module):
    """å®Œæ•´çš„èåˆæ¨¡å‹ï¼Œæ•´åˆå…‰æµã€å…³é”®ç‚¹å’Œèåˆç½‘ç»œ"""
    
    def __init__(self, optical_flow_model, landmark_model, fusion_model):
        """
        åˆå§‹åŒ–å®Œæ•´èåˆæ¨¡å‹
        
        Args:
            optical_flow_model: å…‰æµæ¨¡å‹
            landmark_model: å…³é”®ç‚¹æ¨¡å‹
            fusion_model: èåˆæ¨¡å‹
        """
        super(CompleteFusionModel, self).__init__()
        
        self.optical_flow_model = optical_flow_model
        self.landmark_model = landmark_model
        self.fusion_model = fusion_model
        
        # æ¢¯åº¦ç›‘æ§
        self.gradient_norms = {}
        self.register_gradient_hooks()
    
    def register_gradient_hooks(self):
        """æ³¨å†Œæ¢¯åº¦ç›‘æ§é’©å­"""
        def hook_fn(name):
            def hook(grad):
                if grad is not None:
                    self.gradient_norms[name] = grad.norm().item()
                return grad
            return hook
        
        # ç›‘æ§å…³é”®å±‚çš„æ¢¯åº¦
        if hasattr(self.optical_flow_model, 'classifier'):
            for param in self.optical_flow_model.classifier.parameters():
                param.register_hook(hook_fn('optical_flow_classifier'))
                break
                
        if hasattr(self.landmark_model, 'network'):
            for param in self.landmark_model.network.parameters():
                param.register_hook(hook_fn('landmark_network'))
                break
                
        for param in self.fusion_model.parameters():
            param.register_hook(hook_fn('fusion_model'))
            break
    
    def get_gradient_info(self):
        """è·å–æ¢¯åº¦ä¿¡æ¯ç”¨äºç›‘æ§æ¢¯åº¦æ¶ˆå¤±"""
        return self.gradient_norms.copy()
    
    def check_gradient_health(self, logger=None):
        """
        æ£€æŸ¥æ¢¯åº¦å¥åº·çŠ¶æ€å¹¶å‘å‡ºå‘Šè­¦
        
        Args:
            logger: æ—¥å¿—è®°å½•å™¨
            
        Returns:
            dict: åŒ…å«æ¢¯åº¦å¥åº·çŠ¶æ€çš„å­—å…¸
        """
        import warnings
        
        health_status = {
            'healthy': True,
            'warnings': [],
            'gradient_stats': self.gradient_norms.copy()
        }
        
        # æ¢¯åº¦æ¶ˆå¤±é˜ˆå€¼ (é€šå¸¸å°äº1e-6è¢«è®¤ä¸ºæ˜¯æ¢¯åº¦æ¶ˆå¤±)
        vanishing_threshold = 1e-6
        # æ¢¯åº¦çˆ†ç‚¸é˜ˆå€¼ (å¤§äº100é€šå¸¸è¡¨ç¤ºæ¢¯åº¦çˆ†ç‚¸)
        exploding_threshold = 100.0
        
        for layer_name, grad_norm in self.gradient_norms.items():
            # æ£€æŸ¥æ¢¯åº¦æ¶ˆå¤±
            if grad_norm < vanishing_threshold:
                warning_msg = f"âš ï¸  æ¢¯åº¦æ¶ˆå¤±å‘Šè­¦: {layer_name} å±‚æ¢¯åº¦èŒƒæ•° {grad_norm:.2e} < {vanishing_threshold:.0e}"
                health_status['warnings'].append(warning_msg)
                health_status['healthy'] = False
                
                if logger:
                    logger.warning(warning_msg)
                else:
                    warnings.warn(warning_msg)
                    print(f"ğŸš¨ {warning_msg}")
            
            # æ£€æŸ¥æ¢¯åº¦çˆ†ç‚¸  
            elif grad_norm > exploding_threshold:
                warning_msg = f"ğŸ”¥ æ¢¯åº¦çˆ†ç‚¸å‘Šè­¦: {layer_name} å±‚æ¢¯åº¦èŒƒæ•° {grad_norm:.2f} > {exploding_threshold}"
                health_status['warnings'].append(warning_msg)
                health_status['healthy'] = False
                
                if logger:
                    logger.warning(warning_msg)
                else:
                    warnings.warn(warning_msg)
                    print(f"ğŸš¨ {warning_msg}")
            
            # æ£€æŸ¥å¼‚å¸¸æ¢¯åº¦ (NaNæˆ–Inf)
            elif not (grad_norm == grad_norm) or grad_norm == float('inf'):  # NaNæ£€æŸ¥
                warning_msg = f"ğŸ’¥ å¼‚å¸¸æ¢¯åº¦å‘Šè­¦: {layer_name} å±‚æ¢¯åº¦ä¸º {grad_norm} (NaN/Inf)"
                health_status['warnings'].append(warning_msg)
                health_status['healthy'] = False
                
                if logger:
                    logger.error(warning_msg)
                else:
                    warnings.warn(warning_msg)
                    print(f"ğŸš¨ {warning_msg}")
        
        # å¦‚æœæ¢¯åº¦å¥åº·ï¼Œè¾“å‡ºçŠ¶æ€ä¿¡æ¯
        if health_status['healthy'] and logger:
            grad_summary = ", ".join([f"{name}: {norm:.2e}" for name, norm in self.gradient_norms.items()])
            logger.debug(f"âœ… æ¢¯åº¦å¥åº·çŠ¶æ€è‰¯å¥½ - {grad_summary}")
        
        return health_status
    
    def apply_gradient_clipping(self, max_norm=1.0):
        """åº”ç”¨æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸"""
        total_norm = torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm)
        return total_norm
    
    def handle_gradient_issues(self, logger=None, auto_fix=True):
        """
        è‡ªåŠ¨å¤„ç†æ¢¯åº¦é—®é¢˜
        
        Args:
            logger: æ—¥å¿—è®°å½•å™¨
            auto_fix: æ˜¯å¦è‡ªåŠ¨ä¿®å¤æ¢¯åº¦é—®é¢˜
            
        Returns:
            dict: å¤„ç†ç»“æœ
        """
        health_status = self.check_gradient_health(logger)
        
        if not health_status['healthy'] and auto_fix:
            fix_actions = []
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¢¯åº¦çˆ†ç‚¸
            has_exploding = any('çˆ†ç‚¸' in warning for warning in health_status['warnings'])
            if has_exploding:
                # åº”ç”¨æ¢¯åº¦è£å‰ª
                clipped_norm = self.apply_gradient_clipping(max_norm=1.0)
                fix_msg = f"ğŸ”§ å·²åº”ç”¨æ¢¯åº¦è£å‰ª: åŸå§‹èŒƒæ•° {clipped_norm:.2f} â†’ è£å‰ªåˆ° 1.0"
                fix_actions.append(fix_msg)
                
                if logger:
                    logger.info(fix_msg)
                else:
                    print(fix_msg)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¢¯åº¦æ¶ˆå¤±
            has_vanishing = any('æ¶ˆå¤±' in warning for warning in health_status['warnings'])
            if has_vanishing:
                # å»ºè®®è°ƒæ•´å­¦ä¹ ç‡
                fix_msg = "ğŸ’¡ å»ºè®®æ“ä½œ: æ£€æµ‹åˆ°æ¢¯åº¦æ¶ˆå¤±ï¼Œè€ƒè™‘æé«˜å­¦ä¹ ç‡æˆ–ä½¿ç”¨æ¸è¿›å¼è§£å†»"
                fix_actions.append(fix_msg)
                
                if logger:
                    logger.info(fix_msg)
                else:
                    print(fix_msg)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸æ¢¯åº¦
            has_nan = any('å¼‚å¸¸' in warning for warning in health_status['warnings'])
            if has_nan:
                # é›¶åŒ–å¼‚å¸¸æ¢¯åº¦
                for param in self.parameters():
                    if param.grad is not None:
                        param.grad[param.grad != param.grad] = 0  # å°†NaNè®¾ä¸º0
                        param.grad[param.grad == float('inf')] = 0  # å°†Infè®¾ä¸º0
                        param.grad[param.grad == float('-inf')] = 0  # å°†-Infè®¾ä¸º0
                
                fix_msg = "ğŸ”§ å·²æ¸…ç†å¼‚å¸¸æ¢¯åº¦ (NaN/Inf â†’ 0)"
                fix_actions.append(fix_msg)
                
                if logger:
                    logger.warning(fix_msg)
                else:
                    print(fix_msg)
            
            health_status['fix_actions'] = fix_actions
        
        return health_status
    
    def forward(self, optical_flow_image: torch.Tensor, 
                landmark_features: torch.Tensor) -> torch.Tensor:
        """
        å®Œæ•´å‰å‘ä¼ æ’­
        
        Args:
            optical_flow_image: å…‰æµå›¾åƒï¼Œå½¢çŠ¶ä¸º(batch_size, 3, 112, 112)
            landmark_features: å…³é”®ç‚¹ç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(batch_size, 104)
            
        Returns:
            æœ€ç»ˆé¢„æµ‹ç»“æœï¼Œå½¢çŠ¶ä¸º(batch_size, 2)
        """
        # å…‰æµç‰¹å¾æå–
        optical_features = self.optical_flow_model(optical_flow_image)
        
        # å…³é”®ç‚¹ç‰¹å¾å¤„ç†
        landmark_output = self.landmark_model(landmark_features)
        
        # ç‰¹å¾èåˆ
        final_output = self.fusion_model(optical_features, landmark_output)
        
        return final_output
    
    def freeze_optical_flow_model(self):
        """å†»ç»“å…‰æµæ¨¡å‹"""
        for param in self.optical_flow_model.parameters():
            param.requires_grad = False
    
    def freeze_landmark_model(self):
        """å†»ç»“å…³é”®ç‚¹æ¨¡å‹"""
        for param in self.landmark_model.parameters():
            param.requires_grad = False
    
    def freeze_landmark_fc_layers(self):
        """åªå†»ç»“å…³é”®ç‚¹æ¨¡å‹çš„å…¨è¿æ¥å±‚ï¼Œç”¨äºTFLiteç‰¹å¾æå–å™¨å¾®è°ƒé˜¶æ®µ"""
        # å…³é”®ç‚¹æ¨¡å‹çš„å…¨è¿æ¥ç½‘ç»œéƒ¨åˆ†è¢«å†»ç»“
        # TFLiteéƒ¨åˆ†ä¸éœ€è¦å†»ç»“å› ä¸ºå®ƒä¸å‚ä¸æ¢¯åº¦è®¡ç®—
        if hasattr(self.landmark_model, 'freeze_all'):
            self.landmark_model.freeze_all()
    
    def unfreeze_landmark_fc_layers(self):
        """è§£å†»å…³é”®ç‚¹æ¨¡å‹çš„å…¨è¿æ¥å±‚"""
        if hasattr(self.landmark_model, 'unfreeze_all'):
            self.landmark_model.unfreeze_all()
    
    def get_landmark_trainable_params(self):
        """è·å–å…³é”®ç‚¹æ¨¡å‹çš„å¯è®­ç»ƒå‚æ•°æ•°é‡"""
        if hasattr(self.landmark_model, 'get_trainable_parameters'):
            return self.landmark_model.get_trainable_parameters()
        return sum(p.numel() for p in self.landmark_model.parameters() if p.requires_grad)
    
    def freeze_fusion_model(self):
        """å†»ç»“èåˆæ¨¡å‹"""
        for param in self.fusion_model.parameters():
            param.requires_grad = False
    
    def unfreeze_all(self):
        """è§£å†»æ‰€æœ‰æ¨¡å‹"""
        for param in self.parameters():
            param.requires_grad = True
    
    def progressive_unfreeze(self, stage='early'):
        """
        æ¸è¿›å¼è§£å†»ç­–ç•¥ï¼Œç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
        
        Args:
            stage: 'early' - åªè§£å†»åå‡ å±‚
                  'middle' - è§£å†»ä¸­é—´å±‚
                  'full' - å…¨éƒ¨è§£å†»
        """
        if stage == 'early':
            # åªè§£å†»åˆ†ç±»å™¨å’Œèåˆæ¨¡å‹
            for param in self.optical_flow_model.classifier.parameters():
                param.requires_grad = True
            for param in self.landmark_model.parameters():
                param.requires_grad = True
            for param in self.fusion_model.parameters():
                param.requires_grad = True
                
        elif stage == 'middle':
            # è§£å†»ResNetçš„åå‡ å±‚
            if hasattr(self.optical_flow_model, 'backbone_net'):
                # è§£å†»ResNet18çš„layer4å’Œlayer3
                for layer_name in ['layer4', 'layer3']:
                    if hasattr(self.optical_flow_model.backbone_net, layer_name):
                        layer = getattr(self.optical_flow_model.backbone_net, layer_name)
                        for param in layer.parameters():
                            param.requires_grad = True
        
        elif stage == 'full':
            self.unfreeze_all()
    
    def get_learning_rate_groups(self):
        """
        è·å–ä¸åŒå­¦ä¹ ç‡çš„å‚æ•°ç»„ï¼Œç”¨äºç¼“è§£æ¢¯åº¦æ¶ˆå¤±
        
        Returns:
            å‚æ•°ç»„åˆ—è¡¨ï¼Œæ¯ç»„åŒ…å«å‚æ•°å’Œå»ºè®®å­¦ä¹ ç‡
        """
        groups = []
        
        # èåˆæ¨¡å‹ - æœ€é«˜å­¦ä¹ ç‡
        fusion_params = list(self.fusion_model.parameters())
        if fusion_params:
            groups.append({
                'params': fusion_params,
                'lr_multiplier': 1.0,
                'name': 'fusion'
            })
        
        # å…³é”®ç‚¹æ¨¡å‹ - ä¸­ç­‰å­¦ä¹ ç‡
        landmark_params = list(self.landmark_model.parameters())
        if landmark_params:
            groups.append({
                'params': landmark_params,
                'lr_multiplier': 0.5,
                'name': 'landmark'
            })
        
        # å…‰æµåˆ†ç±»å™¨ - ä¸­ç­‰å­¦ä¹ ç‡
        classifier_params = list(self.optical_flow_model.classifier.parameters())
        if classifier_params:
            groups.append({
                'params': classifier_params,
                'lr_multiplier': 0.5,
                'name': 'optical_classifier'
            })
        
        # ResNet backbone - æœ€ä½å­¦ä¹ ç‡
        if hasattr(self.optical_flow_model, 'backbone_net'):
            backbone_params = list(self.optical_flow_model.backbone_net.parameters())
            if backbone_params:
                groups.append({
                    'params': backbone_params,
                    'lr_multiplier': 0.1,
                    'name': 'optical_backbone'
                })
        
        return groups


def create_fusion_model(config: Dict[str, Any], advanced: bool = False) -> nn.Module:
    """
    åˆ›å»ºèåˆæ¨¡å‹
    
    Args:
        config: æ¨¡å‹é…ç½®
        advanced: æ˜¯å¦ä½¿ç”¨é«˜çº§èåˆæ¨¡å‹
        
    Returns:
        èåˆæ¨¡å‹å®ä¾‹
    """
    if advanced:
        return AdvancedFusionModel(config)
    else:
        return FusionModel(config)
